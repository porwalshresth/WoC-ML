{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "727f2898-e95d-4109-9ac4-ecfb861a4944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mult  | Avg Accuracy | Min (Worst)  | Max (Best)   | Stability\n",
      "-----------------------------------------------------------------\n",
      "x1    | 0.8633       | 0.8225       | 0.8925       | Risky\n",
      "x2    | 0.8640       | 0.8525       | 0.8900       | Stable\n",
      "x3    | 0.8688       | 0.8450       | 0.8850       | Stable\n",
      "x4    | 0.8500       | 0.6475       | 0.8900       | Risky\n",
      "x5    | 0.8662       | 0.8200       | 0.8925       | Risky\n",
      "x6    | 0.8707       | 0.8575       | 0.8825       | Stable\n",
      "x7    | 0.8678       | 0.8300       | 0.8875       | Risky\n",
      "x8    | 0.8650       | 0.8350       | 0.8900       | Risky\n",
      "x9    | 0.8533       | 0.8100       | 0.8875       | Risky\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. SETUP\n",
    "# ---------------------------------------------------------\n",
    "train = pd.read_csv('train.csv')\n",
    "X_raw = train.drop(columns=['id', 'target']).values\n",
    "y_raw = train['target'].values\n",
    "\n",
    "# Split once\n",
    "X_train_raw, X_cv_raw, y_train_raw, y_cv_raw = train_test_split(\n",
    "    X_raw, y_raw, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_cv_scaled = scaler.transform(X_cv_raw)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. THE SCIENTIFIC LOOP (10 Seeds per Multiplier)\n",
    "# ---------------------------------------------------------\n",
    "# We verify multipliers 1 to 9\n",
    "seeds = [1, 2, 3, 4, 5, 42, 100, 2023, 7, 99] \n",
    "\n",
    "print(f\"{'Mult':<5} | {'Avg Accuracy':<12} | {'Min (Worst)':<12} | {'Max (Best)':<12} | {'Stability'}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for multiplier in range(1, 10):\n",
    "    \n",
    "    # Prepare data for this multiplier\n",
    "    train_df = pd.DataFrame(X_train_raw)\n",
    "    train_df['target'] = y_train_raw\n",
    "    red_pills = train_df[train_df['target'] == 0]\n",
    "    blue_pills = train_df[train_df['target'] == 1]\n",
    "    \n",
    "    train_balanced = pd.concat([red_pills] + [blue_pills] * multiplier)\n",
    "    X_train_balanced = train_balanced.drop(columns=['target']).values\n",
    "    y_train_balanced = train_balanced['target'].values\n",
    "    X_train_scaled = scaler.transform(X_train_balanced)\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    # Run 10 times to get the \"True\" performance\n",
    "    for seed in seeds:\n",
    "        # Reset Randomness completely\n",
    "        tf.random.set_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        model = Sequential([\n",
    "            Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "            Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "            Dense(1, activation='linear') \n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001), \n",
    "            loss=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        )\n",
    "        \n",
    "        model.fit(\n",
    "            X_train_scaled, \n",
    "            y_train_balanced, \n",
    "            epochs=50,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        z_cv = model.predict(X_cv_scaled, verbose=0)\n",
    "        yhat_cv = (z_cv >= 0).astype(int).flatten()\n",
    "        accuracies.append(np.mean(yhat_cv == y_cv_raw))\n",
    "        \n",
    "    avg_acc = np.mean(accuracies)\n",
    "    min_acc = np.min(accuracies)\n",
    "    max_acc = np.max(accuracies)\n",
    "    diff = max_acc - min_acc\n",
    "    \n",
    "    # If the difference between Best and Worst run is small, it's Stable.\n",
    "    stability = \"Stable\" if diff < 0.05 else \"Risky\"\n",
    "    \n",
    "    print(f\"x{multiplier:<4} | {avg_acc:.4f}       | {min_acc:.4f}       | {max_acc:.4f}       | {stability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a234292-efad-4233-9f4c-6b7e61b5a9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Lambda Tuning with Blue Pills x6...\n",
      "-----------------------------------------------------------------\n",
      "Lambda     | Avg Accuracy | Min (Worst)  | Stability\n",
      "-----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. SETUP DATA\n",
    "# ---------------------------------------------------------\n",
    "train = pd.read_csv('train.csv')\n",
    "X_raw = train.drop(columns=['id', 'target']).values\n",
    "y_raw = train['target'].values\n",
    "\n",
    "# Split once (Fixed validation set for fair comparison)\n",
    "X_train_raw, X_cv_raw, y_train_raw, y_cv_raw = train_test_split(\n",
    "    X_raw, y_raw, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scaling (Fit on raw training data only)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "X_cv_scaled = scaler.transform(X_cv_raw)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. PREPARE THE WINNER (Multiplier x6)\n",
    "# ---------------------------------------------------------\n",
    "BEST_MULTIPLIER = 6\n",
    "\n",
    "train_df = pd.DataFrame(X_train_raw)\n",
    "train_df['target'] = y_train_raw\n",
    "red_pills = train_df[train_df['target'] == 0]\n",
    "blue_pills = train_df[train_df['target'] == 1]\n",
    "\n",
    "# Create balanced data\n",
    "train_balanced = pd.concat([red_pills] + [blue_pills] * BEST_MULTIPLIER)\n",
    "X_train_balanced = train_balanced.drop(columns=['target']).values\n",
    "y_train_balanced = train_balanced['target'].values\n",
    "\n",
    "# Scale the balanced training data\n",
    "X_train_scaled = scaler.transform(X_train_balanced)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ROBUST LAMBDA TUNING (Averaging over 10 seeds)\n",
    "# ---------------------------------------------------------\n",
    "# Andrew Ng suggests logarithmic scale steps\n",
    "lambda_values = [0.0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1]\n",
    "\n",
    "# We reuse your 10 seeds for maximum rigor\n",
    "seeds = [1, 2, 3, 4, 5, 42, 100, 2023, 7, 99]\n",
    "\n",
    "print(f\"Starting Lambda Tuning with Blue Pills x{BEST_MULTIPLIER}...\")\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'Lambda':<10} | {'Avg Accuracy':<12} | {'Min (Worst)':<12} | {'Stability'}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for lambda_val in lambda_values:\n",
    "    accuracies = []\n",
    "    \n",
    "    # Inner Loop: Run 10 times per lambda\n",
    "    for seed in seeds:\n",
    "        tf.random.set_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        model = Sequential([\n",
    "            Dense(128, activation='relu', kernel_regularizer=l2(lambda_val)),\n",
    "            Dense(64, activation='relu', kernel_regularizer=l2(lambda_val)),\n",
    "            Dense(1, activation='linear') \n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001), \n",
    "            loss=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        )\n",
    "        \n",
    "        model.fit(\n",
    "            X_train_scaled, \n",
    "            y_train_balanced, \n",
    "            epochs=50,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        z_cv = model.predict(X_cv_scaled, verbose=0)\n",
    "        yhat_cv = (z_cv >= 0).astype(int).flatten()\n",
    "        accuracies.append(np.mean(yhat_cv == y_cv_raw))\n",
    "\n",
    "    avg_acc = np.mean(accuracies)\n",
    "    min_acc = np.min(accuracies)\n",
    "    diff = np.max(accuracies) - min_acc\n",
    "    stability = \"Stable\" if diff < 0.05 else \"Risky\"\n",
    "    \n",
    "    print(f\"{lambda_val:<10} | {avg_acc:.4f}       | {min_acc:.4f}       | {stability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b9fc040-6100-462f-b251-bf185c39669e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading full dataset...\n",
      "Applying Blue Pills x6 to the full dataset...\n",
      "Training on 100% of data...\n",
      "Generating submission.csv...\n",
      "Done! Predicted 190 Blue Pills for the Test Set.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. LOAD ALL DATA\n",
    "# ---------------------------------------------------------\n",
    "print(\"Loading full dataset...\")\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Save Test IDs\n",
    "test_ids = test['id']\n",
    "\n",
    "# Prepare Full Arrays (No splitting!)\n",
    "X_raw = train.drop(columns=['id', 'target']).values\n",
    "y_raw = train['target'].values\n",
    "X_test_values = test.drop(columns=['id']).values\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. SCALE ON 100% OF DATA\n",
    "# ---------------------------------------------------------\n",
    "scaler = StandardScaler()\n",
    "# Fit on the ENTIRE training set\n",
    "scaler.fit(X_raw)\n",
    "\n",
    "# Transform everything\n",
    "X_train_scaled = scaler.transform(X_raw)\n",
    "X_test_scaled = scaler.transform(X_test_values)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. APPLY WINNING STRATEGY (x6) TO FULL DATA\n",
    "# ---------------------------------------------------------\n",
    "print(\"Applying Blue Pills x6 to the full dataset...\")\n",
    "\n",
    "# We use the DataFrame logic again for easy filtering\n",
    "train_df = pd.DataFrame(X_train_scaled) # Use scaled data directly\n",
    "train_df['target'] = y_raw\n",
    "\n",
    "red_pills = train_df[train_df['target'] == 0]\n",
    "blue_pills = train_df[train_df['target'] == 1]\n",
    "\n",
    "# Apply x6 Multiplier\n",
    "train_balanced = pd.concat([red_pills] + [blue_pills] * 6)\n",
    "\n",
    "# Extract values for training\n",
    "X_train_final = train_balanced.drop(columns=['target']).values\n",
    "y_train_final = train_balanced['target'].values\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. TRAIN CHAMPION MODEL (Lambda = 0.0)\n",
    "# ---------------------------------------------------------\n",
    "print(\"Training on 100% of data...\")\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "model = Sequential([\n",
    "    # WINNER: Lambda = 0.0\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.0)),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.0)),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_final,\n",
    "    y_train_final,\n",
    "    epochs=50,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. GENERATE SUBMISSION\n",
    "# ---------------------------------------------------------\n",
    "print(\"Generating submission.csv...\")\n",
    "z_test = model.predict(X_test_scaled, verbose=0)\n",
    "predictions = (z_test >= 0).astype(int).flatten()\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'target': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# Optional: Check how many 1s we predicted for the Test Set\n",
    "num_ones = np.sum(predictions)\n",
    "print(f\"Done! Predicted {num_ones} Blue Pills for the Test Set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "539b9348-fa1f-46d4-9145-b9d9ff6cbc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Applying winning strategy: Blue Pills x6...\n",
      "Training the Champion Model...\n",
      "------------------------------\n",
      "Final Sanity Check Accuracy: 0.8825\n",
      "Blue Pills found in CV Set:  11\n",
      "✅ SUCCESS! The model is active and learning.\n",
      "Generating submission.csv...\n",
      "Done! 'submission.csv' is ready for upload.\n",
      "Done! Predicted 175 Blue Pills for the Test Set.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. LOAD DATA\n",
    "# ---------------------------------------------------------\n",
    "print(\"Loading data...\")\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Save test IDs for the submission file\n",
    "test_ids = test['id']\n",
    "\n",
    "# Prepare arrays\n",
    "X_raw = train.drop(columns=['id', 'target']).values\n",
    "y_raw = train['target'].values\n",
    "X_test_values = test.drop(columns=['id']).values\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. THE FINAL SPLIT & SCALE\n",
    "# ---------------------------------------------------------\n",
    "# We keep the split to perform one last \"Sanity Check\" before saving.\n",
    "# It ensures we don't submit a broken model blindly.\n",
    "X_train_raw, X_cv_raw, y_train_raw, y_cv_raw = train_test_split(\n",
    "    X_raw, y_raw, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_raw)\n",
    "\n",
    "X_train_scaled_raw = scaler.transform(X_train_raw)\n",
    "X_cv_scaled = scaler.transform(X_cv_raw)\n",
    "X_test_scaled = scaler.transform(X_test_values)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. APPLY WINNING STRATEGY (Multiplier x6)\n",
    "# ---------------------------------------------------------\n",
    "print(\"Applying winning strategy: Blue Pills x6...\")\n",
    "\n",
    "# Convert back to DF temporarily to filter\n",
    "train_df = pd.DataFrame(X_train_raw)\n",
    "train_df['target'] = y_train_raw\n",
    "\n",
    "red_pills = train_df[train_df['target'] == 0]\n",
    "blue_pills = train_df[train_df['target'] == 1]\n",
    "\n",
    "# Apply x6 Multiplier\n",
    "train_balanced = pd.concat([red_pills] + [blue_pills] * 6)\n",
    "\n",
    "# Extract values again\n",
    "X_train_balanced = train_balanced.drop(columns=['target']).values\n",
    "y_train_balanced = train_balanced['target'].values\n",
    "\n",
    "# Scale the balanced training data\n",
    "X_train_balanced_scaled = scaler.transform(X_train_balanced)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. TRAIN CHAMPION MODEL (Lambda = 0.0)\n",
    "# ---------------------------------------------------------\n",
    "print(\"Training the Champion Model...\")\n",
    "\n",
    "# Set seed for reproducibility\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "model = Sequential([\n",
    "    # WINNER: Lambda = 0.0\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.0)),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.0)),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_balanced_scaled,\n",
    "    y_train_balanced,\n",
    "    epochs=50,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. SANITY CHECK (Crucial Step)\n",
    "# ---------------------------------------------------------\n",
    "z_cv = model.predict(X_cv_scaled, verbose=0)\n",
    "yhat_cv = (z_cv >= 0).astype(int).flatten()\n",
    "acc = np.mean(yhat_cv == y_cv_raw)\n",
    "ones_predicted = np.sum(yhat_cv)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Final Sanity Check Accuracy: {acc:.4f}\")\n",
    "print(f\"Blue Pills found in CV Set:  {ones_predicted}\")\n",
    "\n",
    "if ones_predicted == 0:\n",
    "    print(\"⚠️ STOP! The model is predicting all zeros. Do not submit.\")\n",
    "else:\n",
    "    print(\"✅ SUCCESS! The model is active and learning.\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 6. GENERATE SUBMISSION\n",
    "    # ---------------------------------------------------------\n",
    "    print(\"Generating submission.csv...\")\n",
    "    z_test = model.predict(X_test_scaled, verbose=0)\n",
    "    predictions = (z_test >= 0).astype(int).flatten()\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        'id': test_ids,\n",
    "        'target': predictions\n",
    "    })\n",
    "\n",
    "    submission.to_csv('PredictionsJustOn1600Examples.csv', index=False)\n",
    "    print(\"Done! 'submission.csv' is ready for upload.\")\n",
    "\n",
    "num_ones = np.sum(predictions)\n",
    "print(f\"Done! Predicted {num_ones} Blue Pills for the Test Set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7340a4d-2624-4cb6-a2b6-2510947f27b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
